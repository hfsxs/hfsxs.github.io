

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="扬帆">
  <meta name="keywords" content="">
  
    <meta name="description" content="Prometheus监控Kubernetes集群可通过kube-prometheus方式部署于集群内部，也方便直接调用集群内的认证证书及暴露的监控地址，但将会增加集群的资源开销，也不利于业务的稳定。因此，可以将Prometheus部署于Kubernetes集群之外，也便于监控的集中管理。此时，涉及到的监控指标主要分为三类，即Node节点性能指标（节点CPU、内存、磁盘及网络性能）、Pod及容器资源">
<meta property="og:type" content="article">
<meta property="og:title" content="Prometheus监控Kubernetes集群">
<meta property="og:url" content="https://hfsxs.github.io/2024/05/10/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/index.html">
<meta property="og:site_name" content="扬帆">
<meta property="og:description" content="Prometheus监控Kubernetes集群可通过kube-prometheus方式部署于集群内部，也方便直接调用集群内的认证证书及暴露的监控地址，但将会增加集群的资源开销，也不利于业务的稳定。因此，可以将Prometheus部署于Kubernetes集群之外，也便于监控的集中管理。此时，涉及到的监控指标主要分为三类，即Node节点性能指标（节点CPU、内存、磁盘及网络性能）、Pod及容器资源">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://hfsxs.github.io/img/wiki/prometheus/kubernetes.jpg">
<meta property="og:image" content="https://hfsxs.github.io/img/wiki/prometheus/kubernetes-alerts.jpg">
<meta property="article:published_time" content="2024-05-10T06:59:01.000Z">
<meta property="article:modified_time" content="2025-02-24T08:02:28.629Z">
<meta property="article:author" content="扬帆">
<meta property="article:tag" content="Linux">
<meta property="article:tag" content="云计算">
<meta property="article:tag" content="Docker">
<meta property="article:tag" content="容器">
<meta property="article:tag" content="Kubernetes">
<meta property="article:tag" content="云原生">
<meta property="article:tag" content="Prometheus">
<meta property="article:tag" content="监控告警">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://hfsxs.github.io/img/wiki/prometheus/kubernetes.jpg">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>Prometheus监控Kubernetes集群 - 扬帆</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"hfsxs.github.io","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":100,"cursorChar":"","loop":false,"scope":["home"]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"COPY"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  



  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>扬帆</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">Prometheus监控Kubernetes集群</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-05-10 14:59" pubdate>
          2024年5月10日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          50k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          414 分钟
        
      </span>
    

    
    
      
        <span id="busuanzi_container_page_pv" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="busuanzi_value_page_pv"></span> 次
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Prometheus监控Kubernetes集群</h1>
            
            
              <div class="markdown-body">
                
                <p>Prometheus监控Kubernetes集群可通过kube-prometheus方式部署于集群内部，也方便直接调用集群内的认证证书及暴露的监控地址，但将会增加集群的资源开销，也不利于业务的稳定。因此，可以将Prometheus部署于Kubernetes集群之外，也便于监控的集中管理。此时，涉及到的监控指标主要分为三类，即Node节点性能指标（节点CPU、内存、磁盘及网络性能）、Pod及容器资源性能指标（容器CPU及内存利用率）和Kubernetes集群资源性能指标（controller-manager、kube-scheduler、kube-proxy、Pod、Deployment、Service等状态），具体如下：</p>
<ul>
<li>Node节点监控指标，由节点上部署的node_exporter进行暴露</li>
<li>Pod及容器资源监控指标，由集群组件kubelet内置的cAdvisor（开源的分析容器资源使用率和性能的代理工具）进行暴露，通过kubelet&#x2F;metrics&#x2F;cadvisor接口自动采集节点上所运行容器的CPU、内存、文件系统和网络资源的统计信息，无需做其他配置</li>
<li>Kubernetes集群资源监控指标，则由kube-state-metrics服务进行暴露，通过监听Kubernetes集群ApiServer生成不同资源的状态的Metrics数据，其中8080端口用于暴露Kubernetes集群指标数据，8081端口用于暴露kube-state-metrics服务的指标数据</li>
<li>service-endpoints，通过service的annotation中的相应信息实现</li>
</ul>
<h1 id="1-创建集群外部访问凭证"><a href="#1-创建集群外部访问凭证" class="headerlink" title="1.创建集群外部访问凭证"></a>1.创建集群外部访问凭证</h1><h2 id="1-1-创建RBAC资源文件"><a href="#1-1-创建RBAC资源文件" class="headerlink" title="1.1 创建RBAC资源文件"></a>1.1 创建RBAC资源文件</h2><pre><code class="hljs">vi promethues-rbac.yaml


apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
- apiGroups:
  - &quot;&quot;
  resources:
  - nodes
  - services
  - endpoints
  - pods
  - nodes/proxy
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;extensions&quot;
  resources:
    - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - &quot;&quot;
  resources:
  - configmaps
  - nodes/metrics
  verbs:
  - get
- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
- kind: ServiceAccount
  name: prometheus
  namespace: kube-system
</code></pre>
<h2 id="1-2-创建RBAC"><a href="#1-2-创建RBAC" class="headerlink" title="1.2 创建RBAC"></a>1.2 创建RBAC</h2><pre><code class="hljs">kubectl apply -f promethues-rbac.yaml 
</code></pre>
<h2 id="1-3-创建外部访问凭证"><a href="#1-3-创建外部访问凭证" class="headerlink" title="1.3 创建外部访问凭证"></a>1.3 创建外部访问凭证</h2><pre><code class="hljs">kubectl -n kube-system describe secrets prometheus-token-5stl8 | grep token
vi token.kubernetes


eyJhbGciOiJSUzI1NiIsImtpZCI6InFhd0Q4b2VONWZaTV9fcXBUa1J6dGZZaE83WDhCNG44Uno0QWh3UnpkdTAifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJwcm9tZXRoZXVzLXRva2VuLWxuNXpiIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6InByb21ldGhldXMiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI5NjZlMjdhYy04MWZjLTQ0MTQtODVkOS0xMmJiOWQ0YTI3N2YiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZS1zeXN0ZW06cHJvbWV0aGV1cyJ9.dWeO5OpjI4EewpDeicF6i-DwaYWPL8pwsmXEc8ZZm-OM15KjwZXzFpYIhnkvXPpA38HZOBpNg7gfQewTNZbQdhTrBCLX9UQgGYLzkEnxoxy8VAC0QHGs8tGsSC2dQVhVkwL_Xkgtse9V7ArNHDgfoG_78W3TNjEoDExRtrkUi0pEAFazWWnL9sGm-P1bF6S5iw0mFIydpz8ul4csMvHVYW51iegRHHoLdtdL4o5ys5QIvFGpfJal2JRayRn4IbtlvY-k7b4wSPEBrfZlX0v1_hpk7jPcYek7w9G665A_PeoqSN_OvgyCY9A_FZNDpFek2uH4Jm2gu5vPwSxJp1SJQA
</code></pre>
<h2 id="1-4-将访问凭证发送到Prometheus服务器"><a href="#1-4-将访问凭证发送到Prometheus服务器" class="headerlink" title="1.4 将访问凭证发送到Prometheus服务器"></a>1.4 将访问凭证发送到Prometheus服务器</h2><pre><code class="hljs">scp token.kubernetes node01:/usr/local/prometheus
</code></pre>
<h1 id="2-Kubernetes集群部署kube-state-metrics"><a href="#2-Kubernetes集群部署kube-state-metrics" class="headerlink" title="2.Kubernetes集群部署kube-state-metrics"></a>2.Kubernetes集群部署kube-state-metrics</h1><h2 id="2-1-部署kube-state-metrics"><a href="#2-1-部署kube-state-metrics" class="headerlink" title="2.1 部署kube-state-metrics"></a>2.1 部署kube-state-metrics</h2><pre><code class="hljs">curl -o kube-state-metrics-2.0.0.tar.gz https://github.com/kubernetes/kube-state-metrics/archive/refs/tags/v2.0.0.tar.gz
tar -xzvf kube-state-metrics-2.0.0.tar.gz &amp;&amp; cd kube-state-metrics-2.0.0/examples/standard
kubectl apply -f .
</code></pre>
<h1 id="3-Node节点监控配置"><a href="#3-Node节点监控配置" class="headerlink" title="3.Node节点监控配置"></a>3.Node节点监控配置</h1><p>node_exporter可安装在集群内或集群外，集群内即以DaemonSet方式进行部署</p>
<pre><code class="hljs">- job_name: kubernetes-nodes
  scheme: http 
  tls_config: 
    insecure_skip_verify: true 
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  kubernetes_sd_configs: 
  - role: node 
    api_server: https://172.18.100.100:8443 
    tls_config: 
      insecure_skip_verify: true 
    bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs: 
    - source_labels: [__address__] 
      regex: (.*):10250
      replacement: $&#123;1&#125;:9100
      target_label: __address__ 
      action: replace 
    - action: labelmap 
      regex: __meta_kubernetes_node_label_(.+)
</code></pre>
<h1 id="4-集群组件监控配置"><a href="#4-集群组件监控配置" class="headerlink" title="4.集群组件监控配置"></a>4.集群组件监控配置</h1><h2 id="4-1-api-server监控配置"><a href="#4-1-api-server监控配置" class="headerlink" title="4.1 api-server监控配置"></a>4.1 api-server监控配置</h2><p>api-server的service部署于default命名空间，标签为component&#x3D;apiserver，访问方式为https，端口为6443，因此配置基于service的endpoints服务发现即可</p>
<pre><code class="hljs">- job_name: apiserver
  kubernetes_sd_configs: 
  - role: endpoints
    api_server: https://172.18.100.100:8443
    tls_config: 
      insecure_skip_verify: true
    bearer_token_file: /usr/local/prometheus/token.kubernetes
  scheme: https 
  tls_config: 
    insecure_skip_verify: true 
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs:
  - source_labels: [__meta_kubernetes_namespace,__meta_kubernetes_service_name]
    action: keep
    regex: default;kubernetes
  - source_labels: [__meta_kubernetes_endpoints_name]
    action: replace
    target_label: endpoint
  - source_labels: [__meta_kubernetes_service_name]
    action: replace
    target_label: service
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: namespace
</code></pre>
<h2 id="4-2-controller-manager监控配置"><a href="#4-2-controller-manager监控配置" class="headerlink" title="4.2 controller-manager监控配置"></a>4.2 controller-manager监控配置</h2><p>kube-controller-manager部署于kube-system命名空间，标签为component&#x3D;kube-controller-manager，默认没有配置service</p>
<h3 id="4-2-1-创建service"><a href="#4-2-1-创建service" class="headerlink" title="4.2.1 创建service"></a>4.2.1 创建service</h3><pre><code class="hljs">vi kube-controller-manager-service.yaml


apiVersion: v1
kind: Service
metadata:
  labels:
    k8s-app: kube-controller-manager
  name: kube-controller-manager
  namespace: kube-system
spec:
  selector:
    component: kube-controller-manager
  type: ClusterIP
  clusterIP: None
  ports:
  - name: https-metrics
    port: 10252
    targetPort: 10252
    protocol: TCP
</code></pre>
<h3 id="4-2-2-配置监控端口"><a href="#4-2-2-配置监控端口" class="headerlink" title="4.2.2 配置监控端口"></a>4.2.2 配置监控端口</h3><pre><code class="hljs">sudo vi /etc/kubernetes/manifests/kube-controller-manager.yaml


# 设置端口绑定，允许外部访问
--bind-address=0.0.0.0
# 设置监控端口，默认为0，表示开启https监控端口10257，此处配置文件http监控端口10252
--port=10252
</code></pre>
<h3 id="4-2-3-配置Prometheus"><a href="#4-2-3-配置Prometheus" class="headerlink" title="4.2.3 配置Prometheus"></a>4.2.3 配置Prometheus</h3><pre><code class="hljs">- job_name: kubernetes-controller-manager
  kubernetes_sd_configs:
  - role: pod
    api_server: https://172.18.100.100:8443
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /usr/local/prometheus/token.kubernetes
  scheme: https
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs:
  - source_labels: [__meta_kubernetes_pod_label_component]
    regex: kube-controller-manager
    action: keep
  - source_labels: [__meta_kubernetes_pod_ip]
    regex: (.+)
    target_label: __address__
    replacement: $&#123;1&#125;:10252
  - source_labels: [__meta_kubernetes_endpoints_name]
    action: replace
    target_label: endpoint
  - source_labels: [__meta_kubernetes_pod_name]
    action: replace
    target_label: pod
  - source_labels: [__meta_kubernetes_service_name]
    action: replace
    target_label: service
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: namespace
</code></pre>
<h2 id="4-3-scheduler监控配置"><a href="#4-3-scheduler监控配置" class="headerlink" title="4.3 scheduler监控配置"></a>4.3 scheduler监控配置</h2><p>kube-scheduler部署于kube-system命名空间，匹配Pod对象，标签为component&#x3D;kube-scheduler，默认没有配置service</p>
<h3 id="4-3-1-创建service"><a href="#4-3-1-创建service" class="headerlink" title="4.3.1 创建service"></a>4.3.1 创建service</h3><pre><code class="hljs">vi kube-scheduler.yaml


apiVersion: v1
kind: Service
metadata:
  namespace: kube-system
  name: kube-scheduler
  labels:
    k8s-app: kube-scheduler
spec:
  selector:
    component: kube-scheduler
  type: ClusterIP
  clusterIP: None
  ports:
  - name: http-metrics
    port: 10251
    targetPort: 10251
    protocol: TCP
</code></pre>
<h3 id="4-3-2-配置监控端口"><a href="#4-3-2-配置监控端口" class="headerlink" title="4.3.2 配置监控端口"></a>4.3.2 配置监控端口</h3><pre><code class="hljs">sudo vi /etc/kubernetes/manifests/kube-scheduler.yaml


# 设置端口绑定，允许外部访问
--bind-address=0.0.0.0
# 设置监控端口，默认为0，表示开启https监控端口10259，此处配置文件http监控端口10251
--port=10251
</code></pre>
<h3 id="4-3-3-配置Prometheus"><a href="#4-3-3-配置Prometheus" class="headerlink" title="4.3.3 配置Prometheus"></a>4.3.3 配置Prometheus</h3><pre><code class="hljs">- job_name: kubernetes-scheduler
  kubernetes_sd_configs:
  - role: pod
    api_server: https://172.18.100.100:8443
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /usr/local/prometheus/token.kubernetes
  scheme: https
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs:
  - source_labels: [__meta_kubernetes_pod_label_component]
    regex: kube-scheduler
    action: keep
  - source_labels: [__meta_kubernetes_pod_ip]
    regex: (.+)
    target_label: __address__
    replacement: $&#123;1&#125;:10251
  - source_labels: [__meta_kubernetes_endpoints_name]
    action: replace
    target_label: endpoint
  - source_labels: [__meta_kubernetes_pod_name]
    action: replace
    target_label: pod
  - source_labels: [__meta_kubernetes_service_name]
    action: replace
    target_label: service
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: namespace
</code></pre>
<h2 id="4-4-kubelet监控配置"><a href="#4-4-kubelet监控配置" class="headerlink" title="4.4 kubelet监控配置"></a>4.4 kubelet监控配置</h2><p>kubelet组件集成cAdvisor，通过&#x2F;metrics&#x2F;cadvisor端点暴露容器性能指标，也可通过&#x2F;metrics端点暴露监控指标，端口为10250，role为node</p>
<pre><code class="hljs">- job_name: kubernetes-kubelet
  metrics_path: /metrics/cadvisor
  scheme: https
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  kubernetes_sd_configs:
  - role: node
    api_server: https://172.18.100.100:8443
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs:
  - action: labelmap
    regex: __meta_kubernetes_node_label_(.+)
  - source_labels: [__meta_kubernetes_endpoints_name]
    action: replace
    target_label: endpoint
  - source_labels: [__meta_kubernetes_pod_name]
    action: replace
    target_label: pod
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: namespace
  - source_labels: [__meta_kubernetes_node_address_Hostname]
    action: replace
    target_label: node
</code></pre>
<h2 id="4-5-proxy监控配置"><a href="#4-5-proxy监控配置" class="headerlink" title="4.5 proxy监控配置"></a>4.5 proxy监控配置</h2><p>kube-proxy组件http监控端口为10249，通过&#x2F;metrics暴露监控指标，监控role为endpoints</p>
<h3 id="4-5-1-配置监控端口"><a href="#4-5-1-配置监控端口" class="headerlink" title="4.5.1 配置监控端口"></a>4.5.1 配置监控端口</h3><pre><code class="hljs">kubectl -n kube-system edit configmap kube-proxy


# 设置监控端口，允许外部访问
metricsBindAddress: 0.0.0.0:10249
</code></pre>
<ul>
<li>注：需要重启组件才能生效，kubectl get pods -n kube-system | grep kube-proxy |awk ‘{print $1}’ | xargs kubectl delete pods -n kube-system</li>
</ul>
<h3 id="4-5-2-创建service"><a href="#4-5-2-创建service" class="headerlink" title="4.5.2 创建service"></a>4.5.2 创建service</h3><pre><code class="hljs">sudo vi kube-proxy-service.yaml


apiVersion: v1
kind: Service
metadata:
  labels:
    k8s-app: kube-proxy
  name: kube-proxy
  namespace: kube-system
spec:
  selector:
    k8s-app: kube-proxy
  type: ClusterIP
  clusterIP: None
  ports:
  - name: https-metrics
    port: 10249
    targetPort: 10249
    protocol: TCP
</code></pre>
<h3 id="4-5-2-配置Prometheus"><a href="#4-5-2-配置Prometheus" class="headerlink" title="4.5.2 配置Prometheus"></a>4.5.2 配置Prometheus</h3><pre><code class="hljs">- job_name: kubernetes-proxy
  kubernetes_sd_configs:
  - role: endpoints
    api_server: https://172.18.100.100:8443
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /usr/local/prometheus/token.kubernetes
  scheme: http
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs:
  - source_labels: [__meta_kubernetes_service_name]
    regex: kube-proxy
    action: keep
  - action: labelmap
    regex: __meta_kubernetes_pod_label_(.+)
</code></pre>
<h2 id="4-6-Etcd监控配置"><a href="#4-6-Etcd监控配置" class="headerlink" title="4.6 Etcd监控配置"></a>4.6 Etcd监控配置</h2><p>Etcd启动参数–listen-metrics-url用于指定监控端口与协议，即通过http协议的2381端口对外暴露，且访问地址为本地。因此，需要先修改监控端口的绑定地址为0.0.0.0，才能与Promethues通信</p>
<pre><code class="hljs">- job_name: kubernetes-etcd
  scheme: https
  tls_config:
    ca_file: /etc/kubernetes/pki/etcd/ca.crt
    cert_file: /etc/kubernetes/pki/etcd/server.crt
    key_file: /etc/kubernetes/pki/etcd/server.key
  scrape_interval: 5s
  static_configs:
  - targets: [&#39;172.18.100.101:2379&#39;]
  - targets: [&#39;172.18.100.102:2379&#39;]
  - targets: [&#39;172.18.100.103:2379&#39;]
</code></pre>
<hr>
<pre><code class="hljs">- job_name: etcd
  kubernetes_sd_configs:
  - role: pod
  relabel_configs:
  - source_labels:
      - __meta_kubernetes_pod_label_component
    regex: etcd
    action: keep
  - source_labels: [__meta_kubernetes_pod_ip]
    regex: (.+)
    target_label: __address__
    replacement: $&#123;1&#125;:2381
  - source_labels: [__meta_kubernetes_endpoints_name]
    action: replace
    target_label: endpoint
  - source_labels: [__meta_kubernetes_pod_name]
    action: replace
    target_label: pod
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: namespace
</code></pre>
<h1 id="5-集群资源监控配置"><a href="#5-集群资源监控配置" class="headerlink" title="5.集群资源监控配置"></a>5.集群资源监控配置</h1><h2 id="5-1-Pod及容器监控配置"><a href="#5-1-Pod及容器监控配置" class="headerlink" title="5.1 Pod及容器监控配置"></a>5.1 Pod及容器监控配置</h2><pre><code class="hljs">- job_name: kubernetes-pods 
  scheme: https
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  kubernetes_sd_configs: 
  - role: pod 
    api_server: https://172.18.100.100:8443
    tls_config: 
      insecure_skip_verify: true 
    bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs: 
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
    action: keep
    regex: true
  - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
    action: replace
    target_label: __metrics_path__
    regex: (.+)
  - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
    action: replace
    regex: ([^:]+)(?::\d+)?;(\d+)
    replacement: $1:$2
    target_label: __address__
  - action: labelmap
    regex: __meta_kubernetes_pod_label_(.+)
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: kubernetes_namespace
  - source_labels: [__meta_kubernetes_pod_name]
    action: replace
    target_label: kubernetes_pod_name
</code></pre>
<h2 id="5-2-Services后端Endpoint监控配置"><a href="#5-2-Services后端Endpoint监控配置" class="headerlink" title="5.2 Services后端Endpoint监控配置"></a>5.2 Services后端Endpoint监控配置</h2><pre><code class="hljs">- job_name: kubernetes-service-endpoints
  kubernetes_sd_configs:
  - role: endpoints
    api_server: https://172.18.100.100:8443
    bearer_token_file: /usr/local/prometheus/token.kubernetes
    tls_config:
      insecure_skip_verify: true
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  tls_config:
    insecure_skip_verify: true
  relabel_configs:
  - action: keep
    regex: true
    source_labels:
    - __meta_kubernetes_service_annotation_prometheus_io_scrape
  - action: replace
    regex: (https?)
    source_labels:
    - __meta_kubernetes_service_annotation_prometheus_io_scheme
    target_label: __scheme__
  - action: replace
    regex: (.+)
    source_labels:
    - __meta_kubernetes_service_annotation_prometheus_io_path
    target_label: __metrics_path__
  - action: replace
    regex: ([^:]+)(?::\d+)?;(\d+)
    replacement: $1:$2
    source_labels:
    - __address__
    - __meta_kubernetes_service_annotation_prometheus_io_port
    target_label: __address__
  - action: labelmap
    regex: __meta_kubernetes_service_label_(.+)
  - action: replace
    source_labels:
    - __meta_kubernetes_namespace
    target_label: kubernetes_namespace
  - action: replace
    source_labels:
    - __meta_kubernetes_service_name
    target_label: kubernetes_service_name
</code></pre>
<h2 id="5-3-CoreDNS监控配置"><a href="#5-3-CoreDNS监控配置" class="headerlink" title="5.3 CoreDNS监控配置"></a>5.3 CoreDNS监控配置</h2><p>CoreDNS组件通过service暴露9153监控端口，监控接口为&#x2F;metrics</p>
<pre><code class="hljs">- job_name: kubernetes-coredns
  kubernetes_sd_configs:
  - role: endpoints
    api_server: https://172.18.100.100:8443
    tls_config:
      insecure_skip_verify: true
    bearer_token_file: /usr/local/prometheus/token.kubernetes
  scheme: http
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs:
  - source_labels:
      - __meta_kubernetes_service_label_k8s_app
    regex: kube-dns
    action: keep
  - source_labels: [__meta_kubernetes_pod_ip]
    regex: (.+)
    target_label: __address__
    replacement: $&#123;1&#125;:9153
  - source_labels: [__meta_kubernetes_endpoints_name]
    action: replace
    target_label: endpoint
  - source_labels: [__meta_kubernetes_pod_name]
    action: replace
    target_label: pod
  - source_labels: [__meta_kubernetes_service_name]
    action: replace
    target_label: service
  - source_labels: [__meta_kubernetes_namespace]
    action: replace
    target_label: namespace
</code></pre>
<h2 id="5-4-Service监控配置"><a href="#5-4-Service监控配置" class="headerlink" title="5.4 Service监控配置"></a>5.4 Service监控配置</h2><pre><code class="hljs">- job_name: &quot;kubernetes-services&quot;
  kubernetes_sd_configs:
  - role: service
  metrics_path: /probe
  params:
    module: [http_2xx]
  relabel_configs:
  - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_probe]
    action: keep
    regex: true
  - source_labels: [__address__]
    target_label: __param_target
  - target_label: __address__
    replacement: blackbox-exporter.example.com:9115
  - source_labels: [__param_target]
    target_label: instance
  - action: labelmap
    regex: __meta_kubernetes_service_label_(.+)
  - source_labels: [__meta_kubernetes_namespace]
    target_label: kubernetes_namespace
  - source_labels: [__meta_kubernetes_service_name]
    target_label: kubernetes_name
</code></pre>
<h2 id="5-5-Ingress监控配置"><a href="#5-5-Ingress监控配置" class="headerlink" title="5.5 Ingress监控配置"></a>5.5 Ingress监控配置</h2><pre><code class="hljs">- job_name: &quot;kubernetes-ingresses&quot;
  kubernetes_sd_configs:
  - role: ingress
  relabel_configs:
  - source_labels: [__meta_kubernetes_ingress_annotation_prometheus_io_probe]
    action: keep
    regex: true
  - source_labels: [__meta_kubernetes_ingress_scheme,__address__,__meta_kubernetes_ingress_path]
    regex: (.+);(.+);(.+)
    replacement: $&#123;1&#125;://$&#123;2&#125;$&#123;3&#125;
    target_label: __param_target
  - target_label: __address__
    replacement: blackbox-exporter.example.com:9115
  - source_labels: [__param_target]
    target_label: instance
  - action: labelmap
    regex: __meta_kubernetes_ingress_label_(.+)
  - source_labels: [__meta_kubernetes_namespace]
    target_label: kubernetes_namespace
  - source_labels: [__meta_kubernetes_ingress_name]
    target_label: kubernetes_name
</code></pre>
<h2 id="5-6-kube-state-metrics监控配置"><a href="#5-6-kube-state-metrics监控配置" class="headerlink" title="5.6 kube-state-metrics监控配置"></a>5.6 kube-state-metrics监控配置</h2><pre><code class="hljs">- job_name: kubernetes-state-metrics
  scheme: http
  kubernetes_sd_configs:
  - api_server: https://172.18.100.100:8443
    role: endpoints
    namespaces:
      names: kube-system
    bearer_token_file: /usr/local/prometheus/token.kubernetes
    tls_config:
      insecure_skip_verify: true
  tls_config:
    insecure_skip_verify: true
  bearer_token_file: /usr/local/prometheus/token.kubernetes
  relabel_configs:
  - action: keep
    source_labels: [__meta_kubernetes_service_label_app_kubernetes_io_name]
    regex: kube-state-metrics
  - action: labelmap
    regex: __meta_kubernetes_service_label_(.+)
  - action: replace
    source_labels: [__meta_kubernetes_namespace]
    target_label: kubernetes_namespace
  - action: replace
    source_labels: [__meta_kubernetes_service_name]
    target_label: kubernetes_service_name
</code></pre>
<h1 id="6-配置告警规则"><a href="#6-配置告警规则" class="headerlink" title="6.配置告警规则"></a>6.配置告警规则</h1><pre><code class="hljs">sudo vi /usr/local/prometheus/rules/kubernetes.yml


groups:
- name: kubernetes-system
  rules:
  - alert: KubeVersionMismatch
    annotations:
      description: There are &#123;&#123; $value &#125;&#125; different semantic versions of Kubernetes components running.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeversionmismatch
      summary: Different semantic versions of Kubernetes components running.
    expr: |
      count(count by (git_version) (label_replace(kubernetes_build_info&#123;job!~&quot;kube-dns|coredns&quot;&#125;,&quot;git_version&quot;,&quot;$1&quot;,&quot;git_version&quot;,&quot;(v[0-9]*.[0-9]*).*&quot;))) &gt; 1
    for: 15m
    labels:
      severity: Warning
  - alert: KubeClientErrors
    annotations:
      description: Kubernetes API server client &#39;&#123;&#123; $labels.job &#125;&#125;/&#123;&#123; $labels.instance &#125;&#125;&#39; is experiencing &#123;&#123; $value | humanizePercentage &#125;&#125; errors.&#39;
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeclienterrors
      summary: Kubernetes API server client is experiencing errors.
    expr: |
      (sum(rate(rest_client_requests_total&#123;code=~&quot;5..&quot;&#125;[5m])) by (instance, job)
      /
      sum(rate(rest_client_requests_total[5m])) by (instance, job))
      &gt; 0.01
    for: 15m
    labels:
      severity: Warning

- name: kubernetes-apiserver
  rules:
  - alert: KubeClientCertificateExpiration
    annotations:
      description: A client certificate used to authenticate to the apiserver is expiring in less than 7.0 days.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeclientcertificateexpiration
      summary: Client certificate is about to expire.
    expr: apiserver_client_certificate_expiration_seconds_count&#123;job=&quot;apiserver&quot;&#125; &gt; 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket&#123;job=&quot;apiserver&quot;&#125;[5m]))) &lt; 604800
    labels:
      severity: Warning
  - alert: KubeClientCertificateExpiration
    annotations:
      description: A client certificate used to authenticate to the apiserver is expiring in less than 24.0 hours.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeclientcertificateexpiration
      summary: Client certificate is about to expire.
  expr: |
    apiserver_client_certificate_expiration_seconds_count&#123;job=&quot;apiserver&quot;&#125; &gt; 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket&#123;job=&quot;apiserver&quot;&#125;[5m]))) &lt; 86400
  labels:
    severity: critical
- alert: AggregatedAPIErrors
  annotations:
    description: An aggregated API &#123;&#123; $labels.name &#125;&#125;/&#123;&#123; $labels.namespace &#125;&#125; has reported errors. It has appeared unavailable &#123;&#123; $value | humanize &#125;&#125; times averaged over the past 10m.
    runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/aggregatedapierrors
    summary: An aggregated API has reported errors.
  expr: |
    sum by(name, namespace)(increase(aggregator_unavailable_apiservice_total[10m])) &gt; 4
  labels:
    severity: warning
- alert: AggregatedAPIDown
  annotations:
    description: An aggregated API &#123;&#123; $labels.name &#125;&#125;/&#123;&#123; $labels.namespace &#125;&#125; has been only &#123;&#123; $value | humanize &#125;&#125;% available over the last 10m.
    runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/aggregatedapidown
    summary: An aggregated API is down.
  expr: |
    (1 - max by(name, namespace)(avg_over_time(aggregator_unavailable_apiservice[10m]))) * 100 &lt; 85
  for: 5m
  labels:
    severity: warning
- alert: KubeAPIDown
  annotations:
    description: KubeAPI has disappeared from Prometheus target discovery.
    runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeapidown
    summary: Target disappeared from Prometheus target discovery.
  expr: |
    absent(up&#123;job=&quot;apiserver&quot;&#125; == 1)
  for: 15m
  labels:
    severity: critical
- alert: KubeAPITerminatedRequests
  annotations:
    description: The apiserver has terminated &#123;&#123; $value | humanizePercentage &#125;&#125; of its incoming requests.
    runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeapiterminatedrequests
    summary: The apiserver has terminated &#123;&#123; $value | humanizePercentage &#125;&#125; of its incoming requests.
  expr: |
    sum(rate(apiserver_request_terminations_total&#123;job=&quot;apiserver&quot;&#125;[10m]))  / (  sum(rate(apiserver_request_total&#123;job=&quot;apiserver&quot;&#125;[10m])) + sum(rate(apiserver_request_terminations_total&#123;job=&quot;apiserver&quot;&#125;[10m])) ) &gt; 0.20
  for: 5m
  labels:
    severity: warning

- name: kube-apiserver-slos
  rules:
  - alert: KubeAPIErrorBudgetBurn
    annotations:
      description: The API server is burning too much error budget.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeapierrorbudgetburn
      summary: The API server is burning too much error budget.
    expr: sum(apiserver_request:burnrate1h) &gt; (14.40 * 0.01000) and sum(apiserver_request:burnrate5m) &gt; (14.40 * 0.01000)
    for: 2m
    labels:
      long: 1h
      severity: critical
      short: 5m
  - alert: KubeAPIErrorBudgetBurn
    annotations:
      description: The API server is burning too much error budget.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeapierrorbudgetburn
      summary: The API server is burning too much error budget.
    expr: sum(apiserver_request:burnrate6h) &gt; (6.00 * 0.01000) and sum(apiserver_request:burnrate30m) &gt; (6.00 * 0.01000)
    for: 15m
    labels:
      long: 6h
      severity: critical
      short: 30m
  - alert: KubeAPIErrorBudgetBurn
    annotations:
      description: The API server is burning too much error budget.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeapierrorbudgetburn
      summary: The API server is burning too much error budget.
    expr: sum(apiserver_request:burnrate1d) &gt; (3.00 * 0.01000) and sum(apiserver_request:burnrate2h) &gt; (3.00 * 0.01000)
    for: 1h
    labels:
      long: 1d
      severity: warning
      short: 2h
  - alert: KubeAPIErrorBudgetBurn
    annotations:
      description: The API server is burning too much error budget.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeapierrorbudgetburn
      summary: The API server is burning too much error budget.
    expr: sum(apiserver_request:burnrate3d) &gt; (1.00 * 0.01000) and sum(apiserver_request:burnrate6h) &gt; (1.00 * 0.01000)
    for: 3h
    labels:
      long: 3d
      severity: warning
      short: 6h

- name: kubernetes-scheduler
  rules:
  - alert: KubeSchedulerDown
    annotations:
      description: KubeScheduler has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeschedulerdown
      summary: Target disappeared from Prometheus target discovery.
    expr: absent(up&#123;job=&quot;kube-scheduler&quot;&#125; == 1)
    for: 15m
    labels:
      severity: Critical
- name: kubernetes-controller-manager
  rules:
  - alert: KubeControllerManagerDown
    annotations:
      description: KubeControllerManager has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubecontrollermanagerdown
      summary: Target disappeared from Prometheus target discovery.
    expr: absent(up&#123;job=&quot;kube-controller-manager&quot;&#125; == 1)
    for: 15m
    labels:
      severity: Critical

- name: kubernetes-kubelet
  rules:
  - alert: KubeNodeNotReady
    annotations:
      description: &#39;&#123;&#123; $labels.node &#125;&#125; has been unready for more than 15 minutes.&#39;
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubenodenotready
      summary: Node is not ready.
    expr: kube_node_status_condition&#123;job=&quot;kube-state-metrics&quot;,condition=&quot;Ready&quot;,status=&quot;true&quot;&#125; == 0
    for: 15m
    labels:
      severity: Warning
  - alert: KubeNodeUnreachable
    annotations:
      description: &#39;&#123;&#123; $labels.node &#125;&#125; is unreachable and some workloads may be rescheduled.&#39;
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubenodeunreachable
      summary: Node is unreachable.
    expr: |
      (kube_node_spec_taint&#123;job=&quot;kube-state-metrics&quot;,key=&quot;node.kubernetes.io/unreachable&quot;,effect=&quot;NoSchedule&quot;&#125; unless ignoring(key,value) kube_node_spec_taint&#123;job=&quot;kube-state-metrics&quot;,key=~&quot;ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn&quot;&#125;) == 1
    for: 15m
    labels:
      severity: Warning
  - alert: KubeletTooManyPods
    annotations:
      description: Kubelet &#39;&#123;&#123; $labels.node &#125;&#125;&#39; is running at &#123;&#123; $value | humanizePercentage &#125;&#125; of its Pod capacity.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubelettoomanypods
      summary: Kubelet is running at capacity.
    expr: |
      count by(node) (
        (kube_pod_status_phase&#123;job=&quot;kube-state-metrics&quot;,phase=&quot;Running&quot;&#125; == 1) * on(instance,pod,namespace,cluster) group_left(node) topk by(instance,pod,namespace,cluster) (1, kube_pod_info&#123;job=&quot;kube-state-metrics&quot;&#125;)
      )
      /
      max by(node) (
        kube_node_status_capacity&#123;job=&quot;kube-state-metrics&quot;,resource=&quot;pods&quot;&#125; != 1
      ) &gt; 0.95
    for: 15m
    labels:
      severity: Warning
  - alert: KubeNodeReadinessFlapping
    annotations:
      description: The readiness status of node &#123;&#123; $labels.node &#125;&#125; has changed &#123;&#123; $value &#125;&#125; times in the last 15 minutes.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubenodereadinessflapping
      summary: Node readiness status is flapping.
    expr: sum(changes(kube_node_status_condition&#123;status=&quot;true&quot;,condition=&quot;Ready&quot;&#125;[15m])) by (node) &gt; 2
    for: 15m
    labels:
      severity: Warning
  - alert: KubeletPlegDurationHigh
    annotations:
      description: The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration of &#123;&#123; $value &#125;&#125; seconds on node &#123;&#123; $labels.node &#125;&#125;.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletplegdurationhigh
      summary: Kubelet Pod Lifecycle Event Generator is taking too long to relist.
    expr: node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile&#123;quantile=&quot;0.99&quot;&#125; &gt;= 10
    for: 5m
    labels:
      severity: Warning
  - alert: KubeletPodStartUpLatencyHigh
    annotations:
      description: Kubelet Pod startup 99th percentile latency is &#123;&#123; $value &#125;&#125; seconds on node &#123;&#123; $labels.node &#125;&#125;.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletpodstartuplatencyhigh
      summary: Kubelet Pod startup latency is too high.
    expr: |
      histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket&#123;job=&quot;kubelet&quot;, metrics_path=&quot;/metrics&quot;&#125;[5m])) by (instance, le)) * on(instance) group_left(node) kubelet_node_name&#123;job=&quot;kubelet&quot;, metrics_path=&quot;/metrics&quot;&#125; &gt; 60
    for: 15m
    labels:
      severity: Warning
  - alert: KubeletClientCertificateExpiration
    annotations:
      description: Client certificate for Kubelet on node &#123;&#123; $labels.node &#125;&#125; expires in &#123;&#123; $value | humanizeDuration &#125;&#125;.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletclientcertificateexpiration
      summary: Kubelet client certificate is about to expire.
    expr: kubelet_certificate_manager_client_ttl_seconds &lt; 604800
    labels:
      severity: Warning
  - alert: KubeletClientCertificateExpiration
    annotations:
      description: Client certificate for Kubelet on node &#123;&#123; $labels.node &#125;&#125; expires in &#123;&#123; $value | humanizeDuration &#125;&#125;.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletclientcertificateexpiration
      summary: Kubelet client certificate is about to expire.
    expr: kubelet_certificate_manager_client_ttl_seconds &lt; 86400
    labels:
      severity: Critical
  - alert: KubeletServerCertificateExpiration
    annotations:
      description: Server certificate for Kubelet on node &#123;&#123; $labels.node &#125;&#125; expires in &#123;&#123; $value | humanizeDuration &#125;&#125;.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletservercertificateexpiration
      summary: Kubelet server certificate is about to expire.
    expr: kubelet_certificate_manager_server_ttl_seconds &lt; 604800
    labels:
      severity: Warning
  - alert: KubeletServerCertificateExpiration
    annotations:
      description: Server certificate for Kubelet on node &#123;&#123; $labels.node &#125;&#125; expires in &#123;&#123; $value | humanizeDuration &#125;&#125;.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletservercertificateexpiration
      summary: Kubelet server certificate is about to expire.
    expr: kubelet_certificate_manager_server_ttl_seconds &lt; 86400
    labels:
      severity: Critical
  - alert: KubeletClientCertificateRenewalErrors
    annotations:
      description: Kubelet on node &#123;&#123; $labels.node &#125;&#125; has failed to renew its client certificate (&#123;&#123; $value | humanize &#125;&#125; errors in the last 5 minutes).
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletclientcertificaterenewalerrors
      summary: Kubelet has failed to renew its client certificate.
    expr: increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) &gt; 0
    for: 15m
    labels:
      severity: Warning
  - alert: KubeletServerCertificateRenewalErrors
    annotations:
      description: Kubelet on node &#123;&#123; $labels.node &#125;&#125; has failed to renew its server certificate (&#123;&#123; $value | humanize &#125;&#125; errors in the last 5 minutes).
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletservercertificaterenewalerrors
      summary: Kubelet has failed to renew its server certificate.
    expr: increase(kubelet_server_expiration_renew_errors[5m]) &gt; 0
    for: 15m
    labels:
      severity: Warning
  - alert: KubeletDown
    annotations:
      description: Kubelet has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubeletdown
      summary: Target disappeared from Prometheus target discovery.
    expr: absent(up&#123;job=&quot;kubelet&quot;, metrics_path=&quot;/metrics&quot;&#125; == 1)
    for: 15m
    labels:
      severity: Critical

- name: kubernetes-apps
  rules:
  - alert: KubeContainerWaiting
    annotations:
      description: Pod &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.pod &#125;&#125; container &#123;&#123; $labels.container&#125;&#125; has been in waiting state for longer than 1 hour.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubecontainerwaiting
      summary: Pod container waiting longer than 1 hour
    expr: sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason&#123;job=&quot;kube-state-metrics&quot;&#125;) &gt; 0
    for: 1h
    labels:
      severity: warning
  - alert: KubePodCrashLooping
    annotations:
      description: Pod &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.pod &#125;&#125; (&#123;&#123; $labels.container &#125;&#125;) is restarting &#123;&#123; printf "%.2f" $value &#125;&#125; times / 10 minutes.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubepodcrashlooping
      summary: Pod is crash looping.
    expr: rate(kube_pod_container_status_restarts_total&#123;job=&quot;kube-state-metrics&quot;&#125;[10m]) * 60 * 5 &gt; 0
    for: 15m
    labels:
      severity: Warning
  - alert: KubePodNotReady
    annotations:
      description: Pod &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.pod &#125;&#125; has been in a non-ready state for longer than 15 minutes.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubepodnotready
      summary: Pod has been in a non-ready state for more than 15 minutes.
    expr: sum by (namespace, pod) (max by(namespace, pod) (kube_pod_status_phase&#123;job=&quot;kube-state-metrics&quot;, phase=~&quot;Pending|Unknown&quot;&#125;) * on(namespace, pod) group_left(owner_kind) topk by(namespace, pod) (1, max by(namespace, pod, owner_kind) (kube_pod_owner&#123;owner_kind!=&quot;Job&quot;&#125;))) &gt; 0
    for: 15m
    labels:
      severity: Warning
  - alert: KubeDeploymentGenerationMismatch
    annotations:
      description: Deployment generation for &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.deployment &#125;&#125; does not match, this indicates that the Deployment has failed but has not been rolled back.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubedeploymentgenerationmismatch
      summary: Deployment generation mismatch due to possible roll-back
    expr: kube_deployment_status_observed_generation&#123;job=&quot;kube-state-metrics&quot;&#125; != kube_deployment_metadata_generation&#123;job=&quot;kube-state-metrics&quot;&#125;
    for: 15m
    labels:
      severity: Warning
  - alert: KubeDeploymentReplicasMismatch
    annotations:
      description: Deployment &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.deployment &#125;&#125; has not matched the expected number of replicas for longer than 15 minutes.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubedeploymentreplicasmismatch
      summary: Deployment has not matched the expected number of replicas.
    expr: (kube_deployment_spec_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;!=kube_deployment_status_replicas_available&#123;job=&quot;kube-state-metrics&quot;&#125;) and (changes(kube_deployment_status_replicas_updated&#123;job=&quot;kube-state-metrics&quot;&#125;[10m])==0)
    for: 15m
    labels:
      severity: Warning
  - alert: KubeStatefulSetReplicasMismatch
    annotations:
      description: StatefulSet &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.statefulset &#125;&#125; has not matched the expected number of replicas for longer than 15 minutes.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubestatefulsetreplicasmismatch
      summary: Deployment has not matched the expected number of replicas.
    expr: |
      (
        kube_statefulset_status_replicas_ready&#123;job=&quot;kube-state-metrics&quot;&#125;
          !=
        kube_statefulset_status_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;
      ) and (
        changes(kube_statefulset_status_replicas_updated&#123;job=&quot;kube-state-metrics&quot;&#125;[10m])
          ==
        0
      )
    for: 15m
    labels:
      severity: Warning
  - alert: KubeStatefulSetGenerationMismatch
    annotations:
      description: StatefulSet generation for &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.statefulset &#125;&#125; does not match, this indicates that the StatefulSet has failed but has not been rolled back.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubestatefulsetgenerationmismatch
      summary: StatefulSet generation mismatch due to possible roll-back
    expr: kube_statefulset_status_observed_generation&#123;job=&quot;kube-state-metrics&quot;&#125; != kube_statefulset_metadata_generation&#123;job=&quot;kube-state-metrics&quot;&#125;
    for: 15m
    labels:
      severity: Warning
  - alert: KubeStatefulSetUpdateNotRolledOut
    annotations:
      description: StatefulSet &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.statefulset &#125;&#125; update has not been rolled out.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubestatefulsetupdatenotrolledout
      summary: StatefulSet update has not been rolled out.
    expr: |
      (
        max without (revision) (
          kube_statefulset_status_current_revision&#123;job=&quot;kube-state-metrics&quot;&#125;
            unless
          kube_statefulset_status_update_revision&#123;job=&quot;kube-state-metrics&quot;&#125;
        )
          *
        (
          kube_statefulset_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;
            !=
          kube_statefulset_status_replicas_updated&#123;job=&quot;kube-state-metrics&quot;&#125;
        )
      )  and (
        changes(kube_statefulset_status_replicas_updated&#123;job=&quot;kube-state-metrics&quot;&#125;[5m])
          ==
        0
      )
    for: 15m
    labels:
      severity: Warning
  - alert: KubeDaemonSetRolloutStuck
    annotations:
      description: DaemonSet &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.daemonset &#125;&#125; has not finished or progressed for at least 15 minutes.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubedaemonsetrolloutstuck
      summary: DaemonSet rollout is stuck.
    expr: |
      (
        (
          kube_daemonset_status_current_number_scheduled&#123;job=&quot;kube-state-metrics&quot;&#125;
           !=
          kube_daemonset_status_desired_number_scheduled&#123;job=&quot;kube-state-metrics&quot;&#125;
        ) or (
          kube_daemonset_status_number_misscheduled&#123;job=&quot;kube-state-metrics&quot;&#125;
           !=
          0
        ) or (
          kube_daemonset_updated_number_scheduled&#123;job=&quot;kube-state-metrics&quot;&#125;
           !=
          kube_daemonset_status_desired_number_scheduled&#123;job=&quot;kube-state-metrics&quot;&#125;
        ) or (
          kube_daemonset_status_number_available&#123;job=&quot;kube-state-metrics&quot;&#125;
           !=
          kube_daemonset_status_desired_number_scheduled&#123;job=&quot;kube-state-metrics&quot;&#125;
        )
      ) and (
        changes(kube_daemonset_updated_number_scheduled&#123;job=&quot;kube-state-metrics&quot;&#125;[5m])
          ==
        0
      )
    for: 15m
    labels:
      severity: Warning
  - alert: KubeDaemonSetNotScheduled
    annotations:
      description: &#39;&#123;&#123; $value &#125;&#125; Pods of DaemonSet &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.daemonset &#125;&#125; are not scheduled.&#39;
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubedaemonsetnotscheduled
      summary: DaemonSet pods are not scheduled.
    expr: kube_daemonset_status_desired_number_scheduled&#123;job=&quot;kube-state-metrics&quot;&#125; - kube_daemonset_status_current_number_scheduled&#123;job=&quot;kube-state-metrics&quot;&#125; &gt; 0
    for: 10m
    labels:
      severity: Warning
  - alert: KubeDaemonSetMisScheduled
    annotations:
      description: &#39;&#123;&#123; $value &#125;&#125; Pods of DaemonSet &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.daemonset &#125;&#125; are running where they are not supposed to run.&#39;
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubedaemonsetmisscheduled
      summary: DaemonSet pods are misscheduled.
    expr: kube_daemonset_status_number_misscheduled&#123;job=&quot;kube-state-metrics&quot;&#125; &gt; 0
    for: 15m
    labels:
      severity: Warning
  - alert: KubeJobCompletion
    annotations:
      description: Job &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.job_name &#125;&#125; is taking more than 12 hours to complete.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubejobcompletion
      summary: Job did not complete in time
    expr: kube_job_spec_completions&#123;job=&quot;kube-state-metrics&quot;&#125; - kube_job_status_succeeded&#123;job=&quot;kube-state-metrics&quot;&#125;  &gt; 0
    for: 12h
    labels:
      severity: Warning
  - alert: KubeJobFailed
    annotations:
      description: Job &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.job_name &#125;&#125; failed to complete. Removing failed job after investigation should clear this alert.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubejobfailed
      summary: Job failed to complete.
    expr: kube_job_failed&#123;job=&quot;kube-state-metrics&quot;&#125;  &gt; 0
    for: 15m
    labels:
      severity: Warning
  - alert: KubeHpaReplicasMismatch
    annotations:
      description: HPA &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.hpa &#125;&#125; has not matched the desired number of replicas for longer than 15 minutes.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubehpareplicasmismatch
      summary: HPA has not matched descired number of replicas.
    expr: |
      (kube_hpa_status_desired_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;
        !=
      kube_hpa_status_current_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;)
        and
      (kube_hpa_status_current_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;
        &gt;
      kube_hpa_spec_min_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;)
        and
      (kube_hpa_status_current_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;
        &lt;
      kube_hpa_spec_max_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;)
        and
      changes(kube_hpa_status_current_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;[15m]) == 0
    for: 15m
    labels:
      severity: Warning
  - alert: KubeHpaMaxedOut
    annotations:
      description: HPA &#123;&#123; $labels.namespace &#125;&#125;/&#123;&#123; $labels.hpa &#125;&#125; has been running at max replicas for longer than 15 minutes.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubehpamaxedout
      summary: HPA is running at max replicas
    expr: kube_hpa_status_current_replicas&#123;job=&quot;kube-state-metrics&quot;&#125; == kube_hpa_spec_max_replicas&#123;job=&quot;kube-state-metrics&quot;&#125;
    for: 15m
    labels:
      severity: Warning

- name: kubernetes-resources
  rules:
  - alert: KubeCPUOvercommit
    annotations:
      description: Cluster has overcommitted CPU resource requests for Pods and cannot tolerate node failure.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubecpuovercommit
      summary: Cluster has overcommitted CPU resource requests.
    expr: sum(namespace_cpu:kube_pod_container_resource_requests:sum&#123;&#125;) / sum(kube_node_status_allocatable&#123;resource=&quot;cpu&quot;&#125;)   &gt;
      ((count(kube_node_status_allocatable&#123;resource=&quot;cpu&quot;&#125;) &gt; 1) - 1) / count(kube_node_status_allocatable&#123;resource=&quot;cpu&quot;&#125;)
    for: 5m
    labels:
      severity: Warning
  - alert: KubeMemoryOvercommit
    annotations:
      description: Cluster has overcommitted memory resource requests for Pods and cannot tolerate node failure.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubememoryovercommit
      summary: Cluster has overcommitted memory resource requests.
    expr: |
      sum(namespace_memory:kube_pod_container_resource_requests:sum&#123;&#125;)
      /
      sum(kube_node_status_allocatable&#123;resource=&quot;memory&quot;&#125;)
      &gt;
      ((count(kube_node_status_allocatable&#123;resource=&quot;memory&quot;&#125;) &gt; 1) - 1)
      /
      count(kube_node_status_allocatable&#123;resource=&quot;memory&quot;&#125;)
    for: 5m
    labels:
      severity: Warning
    - alert: KubeCPUQuotaOvercommit
    annotations:
      description: Cluster has overcommitted CPU resource requests for Namespaces.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubecpuquotaovercommit
      summary: Cluster has overcommitted CPU resource requests.
    expr: sum(kube_resourcequota&#123;job=&quot;kube-state-metrics&quot;, type=&quot;hard&quot;, resource=&quot;cpu&quot;&#125;) / sum(kube_node_status_allocatable&#123;resource=&quot;cpu&quot;&#125;) &gt; 1.5
    for: 5m
    labels:
      severity: Warning
  - alert: KubeMemoryQuotaOvercommit
    annotations:
      description: Cluster has overcommitted memory resource requests for Namespaces.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubememoryquotaovercommit
      summary: Cluster has overcommitted memory resource requests.
    expr: sum(kube_resourcequota&#123;job=&quot;kube-state-metrics&quot;, type=&quot;hard&quot;, resource=&quot;memory&quot;&#125;) / sum(kube_node_status_allocatable&#123;resource=&quot;memory&quot;,job=&quot;kube-state-metrics&quot;&#125;) &gt; 1.5
    for: 5m
    labels:
      severity: Warning
  - alert: KubeQuotaAlmostFull
    annotations:
      description: Namespace &#123;&#123; $labels.namespace &#125;&#125; is using &#123;&#123; $value | humanizePercentage &#125;&#125; of its &#123;&#123; $labels.resource &#125;&#125; quota.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubequotaalmostfull
      summary: Namespace quota is going to be full.
    expr: kube_resourcequota&#123;job=&quot;kube-state-metrics&quot;, type=&quot;used&quot;&#125; / ignoring(instance, job, type) (kube_resourcequota&#123;job=&quot;kube-state-metrics&quot;, type=&quot;hard&quot;&#125; &gt; 0) &gt; 0.9 &lt; 1
    for: 15m
    labels:
      severity: Info
  - alert: KubeQuotaFullyUsed
    annotations:
      description: Namespace &#123;&#123; $labels.namespace &#125;&#125; is using &#123;&#123; $value | humanizePercentage &#125;&#125; of its &#123;&#123; $labels.resource &#125;&#125; quota.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubequotafullyused
      summary: Namespace quota is fully used.
    expr: kube_resourcequota&#123;job=&quot;kube-state-metrics&quot;, type=&quot;used&quot;&#125; / ignoring(instance, job, type)
    (kube_resourcequota&#123;job=&quot;kube-state-metrics&quot;, type=&quot;hard&quot;&#125; &gt; 0) == 1
    for: 15m
    labels:
      severity: Info
  - alert: KubeQuotaExceeded
    annotations:
      description: Namespace &#123;&#123; $labels.namespace &#125;&#125; is using &#123;&#123; $value | humanizePercentage &#125;&#125; of its &#123;&#123; $labels.resource &#125;&#125; quota.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubequotaexceeded
      summary: Namespace quota has exceeded the limits.
    expr: kube_resourcequota&#123;job=&quot;kube-state-metrics&quot;, type=&quot;used&quot;&#125; / ignoring(instance, job, type)
    (kube_resourcequota&#123;job=&quot;kube-state-metrics&quot;, type=&quot;hard&quot;&#125; &gt; 0) &gt; 1
    for: 15m
    labels:
      severity: Warning
  - alert: CPUThrottlingHigh
    annotations:
      description: &#39;&#123;&#123; $value | humanizePercentage &#125;&#125; throttling of CPU in namespace &#123;&#123; $labels.namespace &#125;&#125; for container &#123;&#123; $labels.container &#125;&#125; in pod &#123;&#123; $labels.pod &#125;&#125;.&#39;
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/cputhrottlinghigh
      summary: Processes experience elevated CPU throttling.
    expr: sum(increase(container_cpu_cfs_throttled_periods_total&#123;container!=&quot;&quot;, &#125;[5m])) by (container, pod, namespace) /
    sum(increase(container_cpu_cfs_periods_total&#123;&#125;[5m])) by (container, pod, namespace) &gt; ( 25 / 100 )
    for: 15m
    labels:
      severity: Info

- name: kubernetes-storage
  rules:
  - alert: KubePersistentVolumeFillingUp
    annotations:
      description: The PersistentVolume claimed by &#123;&#123; $labels.persistentvolumeclaim &#125;&#125; in Namespace &#123;&#123; $labels.namespace &#125;&#125; is only &#123;&#123; $value | humanizePercentage &#125;&#125; free.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubepersistentvolumefillingup
      summary: PersistentVolume is filling up.
    expr: |
      kubelet_volume_stats_available_bytes&#123;job=&quot;kubelet&quot;, metrics_path=&quot;/metrics&quot;&#125;
      /
      kubelet_volume_stats_capacity_bytes&#123;job=&quot;kubelet&quot;, metrics_path=&quot;/metrics&quot;&#125;
      &lt; 0.03
    for: 1m
    labels:
      severity: Critical
  - alert: KubePersistentVolumeFillingUp
    annotations:
      description: Based on recent sampling, the PersistentVolume claimed by &#123;&#123; $labels.persistentvolumeclaim &#125;&#125; in Namespace &#123;&#123; $labels.namespace &#125;&#125; is expected to fill up within four days. Currently &#123;&#123; $value | humanizePercentage &#125;&#125; is available.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubepersistentvolumefillingup
      summary: PersistentVolume is filling up.
    expr: |
      (
      kubelet_volume_stats_available_bytes&#123;job=&quot;kubelet&quot;, metrics_path=&quot;/metrics&quot;&#125;
      /
      kubelet_volume_stats_capacity_bytes&#123;job=&quot;kubelet&quot;, metrics_path=&quot;/metrics&quot;&#125;
      ) &lt; 0.15
      and
      predict_linear(kubelet_volume_stats_available_bytes&#123;job=&quot;kubelet&quot;, metrics_path=&quot;/metrics&quot;&#125;[6h], 4 * 24 * 3600) &lt; 0
    for: 1h
    labels:
      severity: Warning
  - alert: KubePersistentVolumeErrors
    annotations:
      description: The persistent volume &#123;&#123; $labels.persistentvolume &#125;&#125; has status &#123;&#123; $labels.phase &#125;&#125;.
      runbook_url: https://github.com/prometheus-operator/kube-prometheus/wiki/kubepersistentvolumeerrors
      summary: PersistentVolume is having issues with provisioning.
    expr: kube_persistentvolume_status_phase&#123;phase=~&quot;Failed|Pending&quot;,job=&quot;kube-state-metrics&quot;&#125; &gt; 0
    for: 5m
    labels:
      severity: Critical

- name: kubernetes-coredns
  rules:
  - alert: CoreDNSDown
    annotations:
      message: CoreDNS has disappeared from Prometheus target discovery.
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednsdown
    expr: absent(up&#123;job=&quot;kube-dns&quot;&#125; == 1)
    for: 15m
    labels:
      severity: Critical
  - alert: CoreDNSLatencyHigh
    annotations:
      message: CoreDNS has 99th percentile latency of &#123;&#123; $value &#125;&#125; seconds for server &#123;&#123; $labels.server &#125;&#125; zone &#123;&#123; $labels.zone &#125;&#125; .
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednslatencyhigh
    expr: histogram_quantile(0.99, sum(rate(coredns_dns_request_duration_seconds_bucket&#123;job=&quot;kube-dns&quot;&#125;[5m])) by(server, zone, le)) &gt; 4
    for: 10m
    labels:
      severity: Critical
  - alert: CoreDNSLatencyHigh
    annotations:
      message: CoreDNS has 99th percentile latency of &#123;&#123; $value &#125;&#125; seconds for server &#123;&#123; $labels.server &#125;&#125; zone &#123;&#123; $labels.zone &#125;&#125; .
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednslatencyhigh
    expr: histogram_quantile(0.99, sum(rate(coredns_dns_request_duration_seconds_bucket&#123;job=&quot;kube-dns&quot;&#125;[5m])) by(server, zone, le)) &gt; 4
    for: 10m
    labels:
      severity: Critical
  - alert: CoreDNSErrorsHigh
    annotations:
      message: CoreDNS is returning SERVFAIL for &#123;&#123; $value | humanizePercentage &#125;&#125; of requests.
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednserrorshigh
    expr: sum(rate(coredns_dns_responses_total&#123;job=&quot;kube-dns&quot;,rcode=&quot;SERVFAIL&quot;&#125;[5m])) / sum(rate(coredns_dns_responses_total&#123;job=&quot;kube-dns&quot;&#125;[5m])) &gt; 0.03
    for: 10m
    labels:
      severity: Critical
  - alert: CoreDNSErrorsHigh
    annotations:
      message: CoreDNS is returning SERVFAIL for &#123;&#123; $value | humanizePercentage &#125;&#125; of requests.
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednserrorshigh
    expr: sum(rate(coredns_dns_responses_total&#123;job=&quot;kube-dns&quot;,rcode=&quot;SERVFAIL&quot;&#125;[5m])) / sum(rate(coredns_dns_responses_total&#123;job=&quot;kube-dns&quot;&#125;[5m])) &gt; 0.01
    for: 10m
    labels:
      severity: Critical
  - alert: CoreDNSForwardLatencyHigh
    annotations:
      message: CoreDNS has 99th percentile latency of &#123;&#123; $value &#125;&#125; seconds forwarding requests to &#123;&#123; $labels.to &#125;&#125;.
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednsforwardlatencyhigh
    expr: histogram_quantile(0.99, sum(rate(coredns_forward_request_duration_seconds_bucket&#123;job=&quot;kube-dns&quot;&#125;[5m])) by(to, le)) &gt; 4
    for: 10m
    labels:
      severity: Critical
  - alert: CoreDNSForwardErrorsHigh
    annotations:
      message: CoreDNS is returning SERVFAIL for &#123;&#123; $value | humanizePercentage &#125;&#125; of forward requests to &#123;&#123; $labels.to &#125;&#125;.
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednsforwarderrorshigh
    expr: sum(rate(coredns_forward_responses_total&#123;job=&quot;kube-dns&quot;,rcode=&quot;SERVFAIL&quot;&#125;[5m])) / sum(rate(coredns_forward_responses_total&#123;job=&quot;kube-dns&quot;&#125;[5m])) &gt; 0.03
    for: 10m
    labels:
      severity: Critical
  - alert: CoreDNSForwardErrorsHigh
    annotations:
      message: CoreDNS is returning SERVFAIL for &#123;&#123; $value | humanizePercentage &#125;&#125; of forward requests to &#123;&#123; $labels.to &#125;&#125;.
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednsforwarderrorshigh
    expr: sum(rate(coredns_forward_responses_total&#123;job=&quot;kube-dns&quot;,rcode=&quot;SERVFAIL&quot;&#125;[5m])) / sum(rate(coredns_forward_responses_total&#123;job=&quot;kube-dns&quot;&#125;[5m])) &gt; 0.01
    for: 10m
    labels:
      severity: Critical
  - alert: CoreDNSForwardHealthcheckFailureCount
    annotations:
      message: CoreDNS health checks have failed to upstream server &#123;&#123; $labels.to &#125;&#125;.
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.md#alert-name-corednsforwardhealthcheckfailurecount
    expr: sum(rate(coredns_forward_healthcheck_failures_total&#123;job=&quot;kube-dns&quot;&#125;[5m])) by (to) &gt; 0
    for: 10m
    labels:
      severity: Warning
  - alert: CoreDNSForwardHealthcheckBrokenCount
    annotations:
      message: CoreDNS health checks have failed for all upstream servers.
      runbook_url: https://github.com/povilasv/coredns-mixin/tree/master/runbook.
    expr: sum(rate(coredns_forward_healthcheck_broken_total&#123;job=&quot;kube-dns&quot;&#125;[5m])) &gt; 0
    for: 10m
    labels:
      severity: Warning
  - alert: CorednsPanicCount
    expr: increase(coredns_panics_total[1m]) &gt; 0
    for: 0m
    labels:
      severity: Critical
    annotations:
      summary: &quot;&#123;&#123;$labels.instance&#125;&#125; CoreDNS have Panics.&quot;
      description: &quot;&#123;&#123;$labels.instance&#125;&#125; Number of CoreDNS panics encountered is &#123;&#123; $value &#125;&#125;&quot;
</code></pre>
<h1 id="7-重载Prometheus，验证集群监控状态"><a href="#7-重载Prometheus，验证集群监控状态" class="headerlink" title="7.重载Prometheus，验证集群监控状态"></a>7.重载Prometheus，验证集群监控状态</h1><pre><code class="hljs">curl -XPOST http://127.0.0.1:9090/-/reload
</code></pre>
<h1 id="8-导入grafana模版"><a href="#8-导入grafana模版" class="headerlink" title="8.导入grafana模版"></a>8.导入grafana模版</h1><p>Dashboards —&gt; Manage —&gt; Import —&gt; 模版ID：13105、16420</p>
<p><img src="/img/wiki/prometheus/kubernetes.jpg" srcset="/img/loading.gif" lazyload alt="kubernetes"></p>
<p><img src="/img/wiki/prometheus/kubernetes-alerts.jpg" srcset="/img/loading.gif" lazyload alt="kubernetes-alerts"></p>
<ul>
<li>注：修改计算公式，新增告警持续时长字段：time() - ALERTS_FOR_STATE and ignoring(alertstate) ALERTS</li>
</ul>
<hr>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ul>
<li><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/22623efffc95">https://www.jianshu.com/p/22623efffc95</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/671898732">https://zhuanlan.zhihu.com/p/671898732</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.51cto.com/u_16099314/9650104">https://blog.51cto.com/u_16099314/9650104</a></li>
<li><a target="_blank" rel="noopener" href="https://www.cnblogs.com/suyj/p/16053993.html">https://www.cnblogs.com/suyj/p/16053993.html</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/MrFDd/article/details/134535787">https://blog.csdn.net/MrFDd/article/details/134535787</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34939308/article/details/123314719">https://blog.csdn.net/qq_34939308/article/details/123314719</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_33816243/article/details/126863790">https://blog.csdn.net/qq_33816243/article/details/126863790</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.tianshu.org.cn/docs/setup/monitor-pod-indicator-information">https://docs.tianshu.org.cn/docs/setup/monitor-pod-indicator-information</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E5%B7%A5%E4%BD%9C/" class="category-chain-item">工作</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/Linux/">#Linux</a>
      
        <a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/">#云计算</a>
      
        <a href="/tags/Docker/">#Docker</a>
      
        <a href="/tags/%E5%AE%B9%E5%99%A8/">#容器</a>
      
        <a href="/tags/Kubernetes/">#Kubernetes</a>
      
        <a href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/">#云原生</a>
      
        <a href="/tags/Prometheus/">#Prometheus</a>
      
        <a href="/tags/%E7%9B%91%E6%8E%A7%E5%91%8A%E8%AD%A6/">#监控告警</a>
      
    </div>
  
</div>


              
  

<p class="note note-primary">
<strong> 本文作者: </strong><a href="/">扬帆</a> <br>
<strong> 本文链接: </strong><a href="https://hfsxs.github.io/2024/05/10/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/">https://hfsxs.github.io/2024/05/10/Prometheus%E7%9B%91%E6%8E%A7Kubernetes%E9%9B%86%E7%BE%A4/</a> <br>
<strong> 版权声明: </strong>
    
    
        <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
        <span class="hint--top hint--rounded" aria-label="BY - 署名">
            <i class="iconfont icon-cc-by"></i>
        </span>
        </a>
    
    
</p>




              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/05/16/Linux%E7%B3%BB%E7%BB%9F%E9%85%8D%E7%BD%AE%E7%BD%91%E5%8D%A1bond/" title="Linux系统配置网卡bond">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Linux系统配置网卡bond</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/04/30/Prometheus%E7%9B%91%E6%8E%A7%E9%85%8D%E7%BD%AEMemcached%E7%9B%91%E6%8E%A7%E5%AE%9E%E4%BE%8B/" title="Prometheus监控配置Memcached监控实例">
                        <span class="hidden-mobile">Prometheus监控配置Memcached监控实例</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'hfsxs/hexo-comments');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        总访问量 
        <span id="busuanzi_value_site_pv"></span>
         次
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        总访客数 
        <span id="busuanzi_value_site_uv"></span>
         人
      </span>
    
    
  
</div>

  
  
  

<div>
<span id="timeDate"> 正在载入天数...</span>
<span id="times"> 载入时分秒...</span>
<script>
    var now = new Date();
    function createtime(){
        var grt= new Date("1/12/2025 01:15:00");
        now.setTime(now.getTime()+250);
        days = (now - grt) / 1000 / 60 / 60 / 24;
        dnum = Math.floor(days);
        hours = (now - grt) / 1000 / 60 / 60 - (24 * dnum);
        hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){
            hnum = "0" + hnum;
        }
        minutes = (now - grt) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes);
        if(String(mnum).length ==1 ){
                mnum = "0" + mnum;
        }
        seconds = (now - grt) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds);
        if(String(snum).length ==1 ){
                snum = "0" + snum;
        }
        document.getElementById("timeDate").innerHTML = "🚀本站已飞行 "+dnum+"&nbsp 天";
        document.getElementById("times").innerHTML = hnum + "&nbsp 时 " + mnum + " 分 " + snum + " 秒";
    }
    setInterval("createtime()",250);
</script>
</div>

</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
